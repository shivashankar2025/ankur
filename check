import os
import re
import ssl
import socket
import whois
import requests
import json
from bs4 import BeautifulSoup
from datetime import datetime
from urllib.parse import urlparse, urljoin
from dotenv import load_dotenv
import openai
import gradio as gr
import time
import dns.resolver
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from dateutil import parser
from concurrent.futures import ThreadPoolExecutor
import pandas as pd # Import pandas for CSV handling

# Trusted Certificate Authorities - Expanded List for better coverage
TRUSTED_CAS = [
    "DigiCert", "GlobalSign", "Sectigo", "Entrust", "Let's Encrypt",
    "GoDaddy", "Thawte", "Google Trust Services", "Amazon Trust Services",
    "Cloudflare Inc ECC CA", "ISRGDV", "Apple Inc.", "Microsoft Corporation"
]

# -------------------------------
# ENVIRONMENT SETUP
# -------------------------------

load_dotenv(override=True)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_SAFE_Browse_API_KEY = os.getenv("GOOGLE_SAFE_Browse_API_KEY")

# Check if API keys are loaded
if not OPENAI_API_KEY:
    print("WARNING: OPENAI_API_KEY environment variable not set. AI content analysis will be skipped.")
if not GOOGLE_SAFE_Browse_API_KEY:
    print("WARNING: GOOGLE_SAFE_Browse_API_KEY not set. Safe Browse checks will be skipped.")

# Initialize OpenAI client only if API key is available
client = openai.OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# CSV File Path for Flagged URLs
FLAGGED_URLS_CSV = "flagged_urls.csv"

# -------------------------------
# WEBSITE ANALYZER CLASS
# -------------------------------

class WebsiteSummarizer:
    def __init__(self, model="gpt-4o"):
        self.client = client
        self.model = model
        self.executor = ThreadPoolExecutor(max_workers=8)

        # EXPANDED TRUSTED DOMAINS FOR EXTERNAL RESOURCES
        self.TRUSTED_DOMAINS = [
            'google.com', 'facebook.com', 'amazon.com', 'microsoft.com',
            'apple.com', 'wikipedia.org', 'twitter.com', 'instagram.com', 'linkedin.com',
            'netflix.com', 'reddit.com', 'bing.com', 'yahoo.com', 'ebay.com',
            'cloudflare.com', 'akamai.net', 'bootstrapcdn.com', # Common CDNs/infra
            'googlesyndication.com', 'gstatic.com', 'doubleclick.net', # Google services
            'googleusercontent.com', 'vimeo.com', 'youtube.com', 'ytimg.com', # Video platforms and assets
            'cdn.jsdelivr.net', 'cdnjs.cloudflare.com', 'fonts.googleapis.com', # More common CDNs
            'ajax.googleapis.com', 's.w.org', 'wp.com', # WordPress related
            'm.stripe.com', 'js.stripe.com', # Payment processors
            'assets.braintreegateway.com', # More payment related
            'platform.twitter.com', 'connect.facebook.net', 'google-analytics.com', # Social/Analytics
            'googletagmanager.com', 'adobedtm.com', 'assets.adobedtm.com', # Tag managers / Adobe
            'fonts.gstatic.com', 'gravatar.com', 'secure.gravatar.com', # Fonts and avatars
            'unpkg.com', 'jsdelivr.net', # Package CDNs
            'code.jquery.com', # jQuery CDN
            'cdn.shopify.com', # Shopify CDN
            'cdninstagram.com', # Instagram CDN
            'sentry-cdn.com', # Sentry error tracking
            'cdn.sstatic.net', # Stack Exchange CDN
            'github.githubassets.com', # GitHub's own assets
            'images.ctfassets.net', # Contentful CDN (used by GitHub for some images)
            'avatars.githubusercontent.com', # GitHub user avatars
            'github-cloud.s3.amazonaws.com', # GitHub assets on S3
            'cdn.fontawesome.com', # FontAwesome CDN
            'cdn.segment.com', # Segment CDN
            'use.typekit.net', # Adobe Typekit
            'kit.fontawesome.com', # FontAwesome Kit
            'cdn.cookielaw.org', # Cookie consent platforms
            'cdn.ampproject.org', # AMP Project CDN
            'www.googletagmanager.com', # Google Tag Manager
            'www.google-analytics.com', # Google Analytics
            'www.recaptcha.net', # reCAPTCHA
            'www.gstatic.com', # Google static content
            'maps.gstatic.com', # Google Maps static content
            'apis.google.com', # Google APIs
            'ajax.aspnetcdn.com', # Microsoft ASP.NET CDN
            'az416426.vo.msecnd.net', # Microsoft CDN
            'w.soundcloud.com', # SoundCloud
            'widgets.pinterest.com', # Pinterest
            'code.highcharts.com', # Highcharts CDN
            'stats.g.doubleclick.net', # Google Analytics
            'www.googletagservices.com', # Google Ad Services
            'i.ytimg.com', # YouTube
            's.ytimg.com', 'player.vimeo.com', # YouTube/Vimeo players
            'graph.facebook.com', 'static.addtoany.com', # Social Share
            'cdn.polyfill.io', # Polyfill CDN
            'd3js.org', 'cdnjs.com', # D3.js, another CDN
            'www.google.com' # Google itself
        ]
        self.google_safe_Browse_api_key = GOOGLE_SAFE_Browse_API_KEY
        self.flagged_urls_df = self._load_flagged_urls() # Load flagged URLs on init

    def _load_flagged_urls(self):
        """Loads flagged URLs from CSV or creates an empty DataFrame."""
        if os.path.exists(FLAGGED_URLS_CSV):
            try:
                # Read with converters to ensure 'URL' column is string and 'Timestamp' is datetime
                df = pd.read_csv(FLAGGED_URLS_CSV, converters={'URL': str}, parse_dates=['Timestamp'])
                return df
            except Exception as e:
                print(f"Error loading {FLAGGED_URLS_CSV}: {e}. Creating a new one.")
                return pd.DataFrame(columns=['URL', 'Timestamp'])
        else:
            return pd.DataFrame(columns=['URL', 'Timestamp'])

    def _save_flagged_urls(self):
        """Saves the current DataFrame of flagged URLs to CSV."""
        try:
            self.flagged_urls_df.to_csv(FLAGGED_URLS_CSV, index=False)
            return True, f"URL flagged successfully and saved to {FLAGGED_URLS_CSV}."
        except Exception as e:
            return False, f"Error saving flagged URL to CSV: {e}"

    def flag_url_to_csv(self, url):
        """Adds a URL and timestamp to the flagged URLs CSV."""
        normalized_url = self._normalize_url(url)
        # Check if URL already exists in the DataFrame to avoid duplicates
        if normalized_url in self.flagged_urls_df['URL'].values:
            return False, f"URL '{normalized_url}' is already flagged."

        new_entry = pd.DataFrame([{'URL': normalized_url, 'Timestamp': datetime.now()}])
        self.flagged_urls_df = pd.concat([self.flagged_urls_df, new_entry], ignore_index=True)
        return self._save_flagged_urls() # Save after adding

    def _normalize_url(self, url):
        """Ensures the URL has a scheme for consistent parsing and removes trailing slash if present."""
        if not re.match(r'^[a-zA-Z]+://', url):
            url = 'https://' + url
        parsed_url = urlparse(url)
        # Reconstruct URL without trailing slash for consistent comparison
        # This handles cases like "example.com/" vs "example.com"
        normalized_url = parsed_url.scheme + "://" + parsed_url.netloc + parsed_url.path.rstrip('/')
        if parsed_url.query:
            normalized_url += "?" + parsed_url.query
        if parsed_url.fragment:
            normalized_url += "#" + parsed_url.fragment
        return normalized_url

    def is_valid_url_format(self, url):
        """
        Validates the basic format of a URL and checks for common deceptive patterns.
        Returns (True, message) if valid and potentially safe, (False, message) if invalid or suspicious.
        """
        # Regular expression for a somewhat strict URL validation
        # Allows http/https, optional www, domain, TLD, optional port, path, query, fragment
        regex = re.compile(
            r'^(?:http|ftp|https)://'  # http:// or https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # ...or ip
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)

        if not re.match(regex, url):
            # Check for common "looks like fraud" patterns in poorly formatted URLs
            if " " in url or "\\" in url or "javascript:" in url.lower() or "data:" in url.lower():
                return False, "Invalid URL format or contains dangerous characters. Looks like a fraud attempt."
            if not urlparse(url).netloc: # No network location implies a malformed URL
                return False, "URL does not contain a valid domain name. Not in required format."
            return False, "URL is not in a standard web format (e.g., missing 'http://' or invalid characters)."

        # Further checks for deceptive patterns in valid-looking URLs
        parsed_url = urlparse(url)
        hostname = parsed_url.hostname or ""

        # Punycode check - often used to spoof legitimate domains
        if "xn--" in hostname:
            try:
                decoded_hostname = hostname.encode('utf-8').decode('idna')
                if decoded_hostname != hostname:
                    return False, f"URL contains Punycode ({decoded_hostname}) which can be used for phishing. **HIGH RISK**"
            except Exception:
                pass # Ignore decoding errors, proceed with other checks

        # Look for multiple dots in the domain part that aren't typical for subdomains
        # (e.g., www.google.com.phishing.net)
        domain_parts = hostname.split('.')
        if len(domain_parts) > 3 and not any(tld in hostname for tld in ['.co.uk', '.com.au', '.net.au', '.gov.uk', '.org.uk', '.co.in']):
            # This check is also in is_url_suspicious, but good to have it early for immediate format check.
            # Only flag if it's clearly not a common legitimate structure.
            pass # Let is_url_suspicious handle this more granularly

        # Check for numeric IPs in hostname, already covered by is_url_suspicious but good for immediate format check
        if re.match(r"^\d{1,3}(\.\d{1,3}){3}$", hostname):
            return False, "URL uses an IP address instead of a domain name. This is often suspicious."

        return True, "URL format is standard and appears legitimate."

    def fetch_html_selenium(self, url):
        """Fetches HTML content using Selenium for dynamic content."""
        options = Options()
        options.add_argument("--headless=new")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--window-size=1920,1080")
        options.add_argument("--start-maximized")
        options.add_argument("--disable-infobars")
        options.add_argument("--disable-browser-side-navigation")
        options.add_argument("--disable-extensions")
        options.add_argument("--blink-settings=imagesEnabled=false")
        options.add_argument("--log-level=3")

        driver = None
        try:
            driver = webdriver.Chrome(options=options)
            driver.set_page_load_timeout(30)
            driver.get(url)
            time.sleep(3)
            html = driver.page_source
            return html
        except Exception as e:
            # print(f"Selenium fetch error for {url}: {e}") # Debugging
            return None
        finally:
            if driver:
                driver.quit()

    def check_ssl(self, url):
        """
        Checks SSL certificate validity, issuer, and expiry.
        Returns (True, message) if valid, (False, message) otherwise.
        """
        try:
            parsed = urlparse(url)
            hostname = parsed.hostname
            if not hostname:
                return False, "Invalid URL hostname for SSL check."

            if ':' in hostname:
                hostname = hostname.split(':')[0]

            ctx = ssl.create_default_context()
            with ctx.wrap_socket(socket.socket(), server_hostname=hostname) as s:
                s.settimeout(10)
                s.connect((hostname, 443))
                cert = s.getpeercert()

            issuer_info = {}
            for item in cert['issuer']:
                for k, v in item:
                    issuer_info[k] = v
            issuer_org = issuer_info.get('organizationName', 'Unknown')
            issuer_cn = issuer_info.get('commonName', 'Unknown')

            trusted = any(ca.lower() in issuer_org.lower() or ca.lower() in issuer_cn.lower() for ca in TRUSTED_CAS)

            expiry_date_str = cert.get('notAfter')
            if not expiry_date_str:
                return False, "SSL certificate expiry date not found."

            # Using datetime.strptime to parse the expiry date string
            expiry_date = datetime.strptime(expiry_date_str, '%b %d %H:%M:%S %Y %Z')
            # Calculate days left relative to UTC now
            days_left = (expiry_date - datetime.utcnow()).days

            if days_left < 0:
                return False, f"Expired SSL certificate (expired {abs(days_left)} days ago). **HIGH RISK**"
            if not trusted:
                return False, f"Untrusted SSL certificate issuer: {issuer_org}. **MODERATE RISK**"
            if days_left < 30:
                return True, f"Valid SSL from {issuer_org}, but expires soon ({days_left} days). **LOW RISK**"

            return True, f"Valid SSL from {issuer_org}, expires in {days_left} days."
        except ssl.SSLError as e:
            return False, f"SSL/TLS error: {e}"
        except socket.timeout:
            return False, "SSL/TLS connection timed out."
        except socket.error as e:
            return False, f"Socket error during SSL check: {e}"
        except Exception as e:
            return False, f"General SSL check failed: {e}"

    def is_url_suspicious(self, url):
        """
        Checks for suspicious patterns in the URL.
        Returns (True, message) if suspicious, (False, message) otherwise.
        """
        parsed = urlparse(url)
        suspicion_points = 0
        reasons = []

        if re.match(r"^\d{1,3}(\.\d{1,3}){3}$", parsed.hostname or ""):
            suspicion_points += 2
            reasons.append("IP address used instead of domain name.")

        if re.search(r"(login|verify|secure|update|bank|paypal|account|support|admin|signin)", parsed.hostname or "", re.IGNORECASE):
            suspicion_points += 1
            reasons.append("Suspicious keyword in domain.")

        if parsed.hostname and parsed.hostname.count('.') > 3 and not any(sub in parsed.hostname for sub in ['.co.uk', '.com.au', '.net.au', '.gov.uk', '.org.uk', '.co.in', 'cloudfront.net', 's3.amazonaws.com', 'azureedge.net']): # Exclude common legitimate subdomains
            suspicion_points += 0.5
            reasons.append("Excessive subdomains.")

        if len(url) > 75:
            suspicion_points += 0.5
            reasons.append("Very long URL.")

        path_segments = parsed.path.split('/')
        for segment in path_segments:
            if re.match(r"^[a-zA-Z0-9-]+\.[a-zA-Z]{2,}(?:\.[a-zA-Z]{2,})?$", segment):
                if segment.lower() != parsed.hostname.lower() and segment.replace("www.", "").lower() != parsed.hostname.replace("www.", "").lower():
                    suspicion_points += 2
                    reasons.append(f"Mismatched domain '{segment}' in URL path.")
                    break

        if suspicion_points >= 2:
            return True, f"Suspicious URL patterns detected: {', '.join(reasons)}. **MODERATE RISK**"
        return False, "URL appears clean."

    def check_redirects(self, url):
        """
        Checks for excessive redirects, which can be a sign of obfuscation.
        Returns (True, message) if suspicious, (False, message) otherwise.
        """
        try:
            response = requests.head(url, allow_redirects=True, timeout=10)

            if not response.history and not response.ok:
                response = requests.get(url, allow_redirects=True, timeout=10)

            if len(response.history) >= 3:
                redirect_chain = " -> ".join([r.url for r in response.history] + [response.url])
                return True, f"Excessive redirects detected ({len(response.history)}). Final URL: {response.url}. **MODERATE RISK**"
            return False, "No excessive redirects."
        except requests.exceptions.TooManyRedirects:
            return True, "Too many redirects (loop detected). **HIGH RISK**"
        except requests.RequestException as e:
            return False, f"Redirect check failed: {e}"

    def check_security_headers(self, url):
        """
        Checks for critical HTTP security headers.
        Returns (True, message) if issues, (False, message) otherwise.
        """
        try:
            response = requests.head(url, timeout=10)
            headers = {k.lower(): v for k, v in response.headers.items()}

            missing_headers = []
            if 'x-content-type-options' not in headers or headers['x-content-type-options'].lower() != 'nosniff':
                missing_headers.append('X-Content-Type-Options: nosniff')
            if 'strict-transport-security' not in headers:
                missing_headers.append('Strict-Transport-Security')
            # Content-Security-Policy is very complex, often missing or partial, lower penalty
            if 'content-security-policy' not in headers:
                missing_headers.append('Content-Security-Policy')
            if 'x-frame-options' not in headers or headers['x-frame-options'].lower() not in ['deny', 'sameorigin']:
                missing_headers.append('X-Frame-Options: DENY/SAMEORIGIN')
            # Referrer-Policy can be set to different values, so just checking presence
            if 'referrer-policy' not in headers:
                missing_headers.append('Referrer-Policy')

            if missing_headers:
                return True, f"Missing or insecure HTTP security headers: {', '.join(missing_headers)}. **LOW RISK**"
            return False, "All critical HTTP security headers present."
        except requests.RequestException as e:
            return False, f"Header check failed: {e}"

    def check_for_hotlinked_resources(self, soup, base_url):
        """
        Checks for external resources (images, scripts, stylesheets) linked from suspicious domains.
        This is a heuristic, not an exhaustive check.
        Returns (True, message) if suspicious, (False, message) otherwise.
        """
        hotlinks_found = []
        parsed_base_url = urlparse(base_url)
        base_domain = parsed_base_url.netloc

        for tag_name in ['img', 'script', 'link']:
            for tag in soup.find_all(tag_name):
                src_attr = tag.get('src') or tag.get('href')
                if src_attr:
                    full_src_url = urljoin(base_url, src_attr)
                    parsed_src_url = urlparse(full_src_url)

                    if parsed_src_url.netloc and parsed_src_url.netloc != base_domain:
                        # Check if this external domain is in our expanded trusted list
                        is_trusted_cdn = False
                        for trusted_domain in self.TRUSTED_DOMAINS:
                            # Use .endswith() for better matching of subdomains like 'github.githubassets.com'
                            if parsed_src_url.netloc.endswith(trusted_domain) or parsed_src_url.netloc == trusted_domain:
                                is_trusted_cdn = True
                                break

                        if not is_trusted_cdn:
                            hotlinks_found.append(f"{tag_name} from {parsed_src_url.netloc}")

        if hotlinks_found:
            return True, f"Suspicious external resources detected: {'; '.join(hotlinks_found)}. **LOW RISK**"
        return False, "No suspicious external resources detected."

    def check_forms(self, soup, base_url):
        """
        Checks for suspicious forms (e.g., non-HTTPS action, sensitive fields).
        Returns (count, message).
        """
        forms = soup.find_all('form')
        suspicious_forms_count = 0
        reasons = []

        for i, form in enumerate(forms):
            form_suspicious = False
            action = form.get('action')

            # IMPROVED: Only flag if action explicitly points to HTTP on an HTTPS page
            # Ignore empty action or relative actions which are common for JS-driven forms
            if base_url.startswith('https://') and action and action.startswith('http://'):
                form_suspicious = True
                reasons.append(f"Form {i+1} action points to insecure HTTP ({action}).")

            # Check for sensitive input fields
            sensitive_fields = ['password', 'creditcard', 'cc_number', 'cvv', 'bank_account', 'social_security', 'ssn']
            for field in form.find_all(['input', 'textarea']):
                field_name = field.get('name', '').lower()
                field_type = field.get('type', '').lower()
                if any(sf in field_name for sf in sensitive_fields) or \
                   (field_type == 'password') or \
                   (field_type == 'text' and any(sf in field_name for sf in ['card', 'cc', 'cvv'])):
                    # Check if the form is actually submitting.
                    # This is still a heuristic, as JS can prevent default submission.
                    # For a truly accurate check, network traffic analysis would be needed.
                    if action or form.find('button', {'type': 'submit'}) or form.find('input', {'type': 'submit'}):
                        form_suspicious = True
                        reasons.append(f"Form {i+1} contains sensitive input fields ({field_name}).")
                        break

            if form_suspicious:
                suspicious_forms_count += 1

        if suspicious_forms_count > 0:
            return suspicious_forms_count, f"{suspicious_forms_count} suspicious form(s) found: {'; '.join(reasons)}. **HIGH RISK**"
        return 0, "No suspicious forms detected."

    def check_blacklists(self, url):
        """
        Placeholder for external blacklist checks.
        Returns (True, message) if blacklisted, (False, message) otherwise.
        """
        known_bad_domains = ["phishing.example.com", "malware.test.net"] # Dummy list
        parsed_url = urlparse(url)
        if parsed_url.hostname in known_bad_domains:
            return True, "Found on internal dummy blacklist. **CRITICAL RISK**"

        return False, "Not found on simple blacklists (further checks recommended)."

    def check_google_safe_Browse(self, url):
        """
        Checks a URL against the Google Safe Browse API (Lookup API v4).
        Returns (True, "Reason") if unsafe, (False, "Reason") if safe or API error.
        """
        if not self.google_safe_Browse_api_key:
            return False, "Google Safe Browse API key not configured. Check skipped."
        api_url = f"https://safeBrowse.googleapis.com/v4/threatMatches:find?key={self.google_safe_Browse_api_key}"

        normalized_url = self._normalize_url(url)

        headers = {"Content-Type": "application/json"}
        payload = {
            "client": {
                "clientId": "web-summary-fraud-checker",
                "clientVersion": "1.0.0"
            },
            "threatInfo": {
                "threatTypes": ["MALWARE", "SOCIAL_ENGINEERING", "UNWANTED_SOFTWARE", "POTENTIALLY_HARMFUL_APPLICATION"],
                "platformTypes": ["ANY_PLATFORM"],
                "threatEntryTypes": ["URL"],
                "threatEntries": [{"url": normalized_url}]
            }
        }

        try:
            response = requests.post(api_url, headers=headers, json=payload, timeout=10)
            response.raise_for_status()

            data = response.json()

            if "matches" in data and data["matches"]:
                threats = []
                for match in data["matches"]:
                    threats.append(f"{match.get('threatType', 'UNKNOWN')}")
                return True, f"Found on Google Safe Browse list: {', '.join(threats)}. **CRITICAL RISK - AVOID THIS SITE!**"
            else:
                return False, "Not found on Google Safe Browse lists."

        except requests.exceptions.HTTPError as e:
            return False, f"Safe Browse API HTTP error: {e.response.status_code} - {e.response.text}"
        except requests.exceptions.ConnectionError as e:
            return False, f"Safe Browse API connection error: {e}"
        except requests.exceptions.Timeout:
            return False, "Safe Browse API request timed out."
        except json.JSONDecodeError:
            return False, "Safe Browse API returned invalid JSON response."
        except Exception as e:
            return False, f"An unexpected error occurred during Safe Browse check: {e}"

    def check_minimal_content(self, text):
        """Checks if the content is too sparse, often a sign of incomplete or malicious sites."""
        if len(text) < 200:
            return True, "Minimal content detected. Could be under construction or a placeholder. **LOW RISK**"
        return False, "Sufficient content detected."

    def analyze_content_with_ai(self, text):
        """
        Uses OpenAI to classify content as safe, suspicious, or fraudulent.
        """
        if not self.client:
            return "skipped", "OpenAI API key not configured. AI analysis skipped."

        prompt = f"""
Analyze the following website content for signs of being a scam or phishing website.
Look for:
- Urgency (e.g., "Act now!", "Your account will be suspended!")
- Financial requests (e.g., "Confirm your bank details", "Claim your prize money")
- Poor grammar, spelling mistakes, or unprofessional language
- Login prompts for sensitive information (e.g., banking, email, social media)
- Mismatched branding or logos
- Unrealistic offers or claims
- Requests for personal information (SSN, credit card, etc.)

Based on these indicators, categorize the content as 'safe', 'suspicious', or 'fraudulent'.
Provide only one of these three words as your direct answer, followed by a brief reason if suspicious/fraudulent.
Content:
{text[:4000]}
"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100
            )
            decision = response.choices[0].message.content.strip().lower()

            if "fraudulent" in decision or "fraud" in decision:
                return "fraudulent", "AI classified as fraudulent."
            elif "suspicious" in decision:
                return "suspicious", "AI classified as suspicious."
            return "safe", "AI classified as safe."

        except openai.APIConnectionError as e:
            return "error", f"OpenAI connection error: {e}"
        except openai.RateLimitError:
            return "error", "OpenAI rate limit hit."
        except openai.APIStatusError as e:
            return "error", f"OpenAI API error: {e.status_code} - {e.response}"
        except Exception as e:
            return "error", f"AI content analysis failed: {e}"

    def check_suspicious_javascript(self, html_content):
        """
        Performs a basic check for suspicious JavaScript patterns.
        This is a heuristic and not a substitute for a real JS sandbox.
        """
        suspicious_js_patterns = [
            r"document\.write\(unescape\(",
            r"eval\(",
            r"setTimeout\(\s*['\"]",
            r"window\.location\.href\s*=\s*['\"`/]",
            r"history\.pushState",
            r"atob\(",
            r"String\.fromCharCode\(",
            r"\.innerHTML\s*=\s*['\"`]",
            r"addEventListener\(['\"]click['\"],.*?window\.open",
            r"form\.submit\(\)",
        ]

        reasons = []
        for pattern in suspicious_js_patterns:
            if re.search(pattern, html_content, re.IGNORECASE | re.DOTALL):
                reasons.append(f"Pattern '{pattern}' found.")

        if reasons:
            return True, f"Suspicious JavaScript patterns detected: {'; '.join(reasons)}. **MODERATE RISK**"
        return False, "No highly suspicious JavaScript patterns detected."


    def summarize(self, url):
        """
        Main method to summarize and perform comprehensive fraud checks on a URL.
        """
        # Step 0: Normalize URL first for consistent checking
        normalized_url = self._normalize_url(url)

        # Step 1: Check if URL is already flagged
        if normalized_url in self.flagged_urls_df['URL'].values:
            flag_time = self.flagged_urls_df[self.flagged_urls_df['URL'] == normalized_url]['Timestamp'].iloc[0]
            summary = f"⚠️ This URL ('{normalized_url}') was previously flagged on {flag_time.strftime('%Y-%m-%d %H:%M:%S')}. No further fraud checks performed."
            detailed_report = f"""
---
### Overall Verdict: **Previously Flagged ⚠️**
---
This URL was found in your flagged URLs list.
**URL:** `{normalized_url}`
**Flagged On:** {flag_time.strftime('%Y-%m-%d %H:%M:%S')}
No new fraud analysis was performed as it's already marked.
"""
            return summary, detailed_report

        # Step 2: Validate URL format and initial patterns
        is_valid_format, url_format_msg = self.is_valid_url_format(url)

        summary = "N/A"
        detailed_report = ""
        score = 100 # Start with a perfect score

        # Immediate and heavy penalty for invalid URL format
        if not is_valid_format:
            score -= 60  # Increased penalty for URL format issues
            final_verdict_line = "Likely Fraudulent ❌"
            summary = f"❌ The provided URL is not in a required format or looks like a fraud website: {url_format_msg}"

            # Populate report messages for skipped checks
            ssl_is_safe, ssl_msg = False, "SSL check skipped (invalid URL)."
            suspicious_url_flag, suspicious_url_msg = False, "URL pattern check skipped (invalid URL)."
            redirects_flag, redirects_msg = False, "Redirect check skipped (invalid URL)."
            headers_issues_flag, headers_msg = False, "Header check skipped (invalid URL)."
            blacklist_flag, blacklist_msg = False, "Blacklist check skipped (invalid URL)."
            safe_Browse_unsafe, safe_Browse_msg = False, "Google Safe Browse check skipped (invalid URL)."
            hotlinking_flag, hotlinking_msg = False, "External resource check skipped (invalid URL)."
            form_count, form_msg = 0, "Form check skipped (invalid URL)."
            minimal_content_flag, minimal_content_msg = False, "Minimal content check skipped (invalid URL)."
            content_ai_status, content_ai_msg = "skipped", "AI analysis skipped (invalid URL)."
            js_behavior_flag, js_behavior_msg = False, "JavaScript check skipped (invalid URL)."

            detailed_report = f"""
---
### Overall Verdict: **{final_verdict_line}** (Score: {max(0, score)}/100)
---
### Key Security Indicators:
- **URL Format Validation:** {'✅ ' if is_valid_format else '❌ '}{url_format_msg}
- **Website Accessibility:** ❌ Failed to fetch content via Selenium. Site might be down, blocked, or not exist. **CRITICAL RISK**
- **SSL/TLS Certificate:** {'✅ ' if ssl_is_safe else ('⚠️ ' if ssl_is_safe and "expires soon" not in ssl_msg else '❌ ')}{ssl_msg}
- **Suspicious URL Pattern:** {'❌ ' if suspicious_url_flag else '✅ '}{suspicious_url_msg}
- **Excessive Redirects:** {'❌ ' if redirects_flag else '✅ '}{redirects_msg}
- **Missing HTTP Security Headers:** {'❌ ' if headers_issues_flag else '✅ '}{headers_msg}
- **Custom Blacklist Check:** {'❌ ' if blacklist_flag else '✅ '}{blacklist_msg}
- **Google Safe Browse:** {'❌ ' if safe_Browse_unsafe else '✅ '}{safe_Browse_msg}
- **Suspicious External Resources (Hotlinking):** {'❌ ' if hotlinking_flag else '✅ '}{hotlinking_msg}
- **Suspicious Forms Detected:** {'❌ ' if form_count > 0 else '✅ '}{form_msg}
- **Minimal Content Detected:** {'⚠️ ' if minimal_content_flag else '✅ '}{minimal_content_msg}
- **AI Content Analysis:** {'❌ ' if content_ai_status == "fraudulent" else ('⚠️ ' if content_ai_status == "suspicious" else '✅ ')}{content_ai_msg}
- **Suspicious JavaScript Behavior:** {'❌ ' if js_behavior_flag else '✅ '}{js_behavior_msg}

---
"""
            return summary, detailed_report

        html_content = self.fetch_html_selenium(normalized_url)

        if not html_content:
            summary = "❌ Could not fetch website content using Selenium. The site might be down, blocked, or not exist."
            score = 10 # Very low score for unreachability
            final_verdict_line = "Likely Fraudulent ❌"

            # Populate report messages for skipped checks due to unreachability
            ssl_is_safe, ssl_msg = False, "SSL check skipped (site unreachable)."
            suspicious_url_flag, suspicious_url_msg = False, "URL pattern check skipped (site unreachable)."
            redirects_flag, redirects_msg = False, "Redirect check skipped (site unreachable)."
            headers_issues_flag, headers_msg = False, "Header check skipped (site unreachable)."
            blacklist_flag, blacklist_msg = False, "Blacklist check skipped (site unreachable)."
            safe_Browse_unsafe, safe_Browse_msg = False, "Google Safe Browse check skipped (site unreachable)."
            hotlinking_flag, hotlinking_msg = False, "External resource check skipped (site unreachable)."
            form_count, form_msg = 0, "Form check skipped (site unreachable)."
            minimal_content_flag, minimal_content_msg = False, "Minimal content check skipped (site unreachable)."
            content_ai_status, content_ai_msg = "skipped", "AI analysis skipped (site unreachable)."
            js_behavior_flag, js_behavior_msg = False, "JavaScript check skipped (site unreachable)."

            detailed_report = f"""
---
### Overall Verdict: **{final_verdict_line}** (Score: {max(0, score)}/100)
---
### Key Security Indicators:
- **URL Format Validation:** {'✅ ' if is_valid_format else '❌ '}{url_format_msg}
- **Website Accessibility:** ❌ Failed to fetch content via Selenium. Site might be down, blocked, or not exist. **CRITICAL RISK**
- **SSL/TLS Certificate:** {'✅ ' if ssl_is_safe else ('⚠️ ' if ssl_is_safe and "expires soon" not in ssl_msg else '❌ ')}{ssl_msg}
- **Suspicious URL Pattern:** {'❌ ' if suspicious_url_flag else '✅ '}{suspicious_url_msg}
- **Excessive Redirects:** {'❌ ' if redirects_flag else '✅ '}{redirects_msg}
- **Missing HTTP Security Headers:** {'❌ ' if headers_issues_flag else '✅ '}{headers_msg}
- **Custom Blacklist Check:** {'❌ ' if blacklist_flag else '✅ '}{blacklist_msg}
- **Google Safe Browse:** {'❌ ' if safe_Browse_unsafe else '✅ '}{safe_Browse_msg}
- **Suspicious External Resources (Hotlinking):** {'❌ ' if hotlinking_flag else '✅ '}{hotlinking_msg}
- **Suspicious Forms Detected:** {'❌ ' if form_count > 0 else '✅ '}{form_msg}
- **Minimal Content Detected:** {'⚠️ ' if minimal_content_flag else '✅ '}{minimal_content_msg}
- **AI Content Analysis:** {'❌ ' if content_ai_status == "fraudulent" else ('⚠️ ' if content_ai_status == "suspicious" else '✅ ')}{content_ai_msg}
- **Suspicious JavaScript Behavior:** {'❌ ' if js_behavior_flag else '✅ '}{js_behavior_msg}

---
"""
            return summary, detailed_report

        futures = {
            self.executor.submit(self.check_ssl, normalized_url): "ssl_check",
            self.executor.submit(self.is_url_suspicious, normalized_url): "suspicious_url",
            self.executor.submit(self.check_redirects, normalized_url): "redirects",
            self.executor.submit(self.check_security_headers, normalized_url): "headers",
            self.executor.submit(self.check_blacklists, normalized_url): "blacklist",
            self.executor.submit(self.check_google_safe_Browse, normalized_url): "google_safe_Browse",
        }

        results = {}
        for future in futures:
            key = futures[future]
            try:
                results[key] = future.result()
            except Exception as e:
                results[key] = (False, f"Check failed: {e}")

        ssl_is_safe, ssl_msg = results["ssl_check"]
        suspicious_url_flag, suspicious_url_msg = results["suspicious_url"]
        redirects_flag, redirects_msg = results["redirects"]
        headers_issues_flag, headers_msg = results["headers"]
        blacklist_flag, blacklist_msg = results["blacklist"]
        safe_Browse_unsafe, safe_Browse_msg = results["google_safe_Browse"]

        soup = BeautifulSoup(html_content, 'html.parser')
        text_content = soup.get_text(separator=' ', strip=True)
        trimmed_text_content = text_content[:6000]

        hotlinking_flag, hotlinking_msg = self.check_for_hotlinked_resources(soup, normalized_url)
        form_count, form_msg = self.check_forms(soup, normalized_url)
        minimal_content_flag, minimal_content_msg = self.check_minimal_content(trimmed_text_content)
        content_ai_status, content_ai_msg = self.analyze_content_with_ai(trimmed_text_content)
        js_behavior_flag, js_behavior_msg = self.check_suspicious_javascript(html_content)

        if self.client:
            try:
                chat_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": f"Summarize the following website content:\n\n{trimmed_text_content[:2000]}"}],
                    max_tokens=300
                )
                summary = chat_response.choices[0].message.content.strip()
            except Exception as e:
                summary = f"❌ OpenAI API error during summarization: {e}"
        else:
            summary = "AI summarization skipped due to missing API key."

        # --- Corrected Scoring Logic (for reachable sites with valid format) ---
        # The base score is 100. Penalties reduce the score.
        # URL Format Validation: Handled by early exit with heavy penalty if invalid.
        # If we reached here, the format is considered good, so no penalty for this check.
        # Website Accessibility: Handled by early exit with low score if unreachable.
        # If we reached here, the site is accessible, so no penalty for this check.
        # SSL/TLS Certificate (Very High Importance)
        if not ssl_is_safe:
            if "Expired" in ssl_msg:
                score -= 35  # Increased penalty
            elif "Untrusted" in ssl_msg:
                score -= 30  # Increased penalty
            else:
                score -= 20
        else:
            if "expires soon" in ssl_msg:
                score -= 10  # Increased penalty for expiring soon
            # No bonus for a valid, healthy SSL; it's the expected state for a 100 score.

        # Suspicious URL Pattern (Very High Importance)
        if suspicious_url_flag:
            score -= 30  # Increased penalty

        # Google Safe Browse (Critical Importance)
        if safe_Browse_unsafe:
            score -= 100 # This remains the highest penalty as it's an official threat list.
        # Blacklist (High Importance)
        if blacklist_flag:
            score -= 50

        # Excessive Redirects (Moderate Importance)
        if redirects_flag:
            score -= 15 # Slightly increased penalty

        # Suspicious JavaScript Behavior (Moderate Importance)
        if js_behavior_flag:
            score -= 20 # Slightly increased penalty

        # Suspicious Forms Detected (High Importance)
        if form_count > 0:
            score -= (form_count * 10) # Increased penalty per suspicious form

        # AI Content Analysis (High Importance)
        if content_ai_status == "suspicious":
            score -= 25 # Increased AI penalty
        elif content_ai_status == "fraudulent":
            score -= 70 # Increased AI penalty

        # Minimal Content Detected (Lower Importance)
        if minimal_content_flag:
            score -= 5 # Reduced penalty, as legitimate sites can also have minimal content (e.g., landing pages).
        # Missing HTTP Security Headers (Lower Importance - often missing even on legitimate sites)
        if headers_issues_flag:
            score -= 2 # Further reduced penalty

        # Suspicious External Resources (Hotlinking) (Lower Importance - can be legitimate CDNs)
        if hotlinking_flag:
            score -= 3 # Further reduced penalty


        score = max(0, score) # Ensure score doesn't go below 0

        if score >= 80: # Adjusted threshold for "Likely Safe"
            final_verdict_line = "Likely Safe ✅"
        elif score >= 50: # Adjusted threshold for "Suspicious"
            final_verdict_line = "Suspicious ⚠️"
        else:
            final_verdict_line = "Likely Fraudulent ❌"

        detailed_report = f"""
---
### Overall Verdict: **{final_verdict_line}** (Score: {score}/100)
---
### Key Security Indicators:
- **URL Format Validation:** {'✅ ' if is_valid_format else '❌ '}{url_format_msg}
- **Website Accessibility:** {'✅ ' if html_content else '❌ '}{'Site content fetched successfully.' if html_content else 'Failed to fetch content.'}
- **SSL/TLS Certificate:** {'✅ ' if ssl_is_safe and "expires soon" not in ssl_msg else ('⚠️ ' if ssl_is_safe else '❌ ')}{ssl_msg}
- **Suspicious URL Pattern:** {'❌ ' if suspicious_url_flag else '✅ '}{suspicious_url_msg}
- **Excessive Redirects:** {'❌ ' if redirects_flag else '✅ '}{redirects_msg}
- **Missing HTTP Security Headers:** {'❌ ' if headers_issues_flag else '✅ '}{headers_msg}
- **Custom Blacklist Check:** {'❌ ' if blacklist_flag else '✅ '}{blacklist_msg}
- **Google Safe Browse:** {'❌ ' if safe_Browse_unsafe else '✅ '}{safe_Browse_msg}
- **Suspicious External Resources (Hotlinking):** {'❌ ' if hotlinking_flag else '✅ '}{hotlinking_msg}
- **Suspicious Forms Detected:** {'❌ ' if form_count > 0 else '✅ '}{form_msg}
- **Minimal Content Detected:** {'⚠️ ' if minimal_content_flag else '✅ '}{minimal_content_msg}
- **AI Content Analysis:** {'❌ ' if content_ai_status == "fraudulent" else ('⚠️ ' if content_ai_status == "suspicious" else '✅ ')}{content_ai_msg}
- **Suspicious JavaScript Behavior:** {'❌ ' if js_behavior_flag else '✅ '}{js_behavior_msg}

---
### Website Summary (via AI):
{summary}
---
"""
        return summary, detailed_report

# Gradio Interface functions
summarizer_instance = WebsiteSummarizer() # Create a single instance of the summarizer

def analyze_url_gradio(url):
    """Function to be called by Gradio for analysis."""
    _, detailed_report = summarizer_instance.summarize(url)
    return detailed_report

def flag_current_url_gradio(url_input):
    """Function to be called by Gradio's flag button."""
    if not url_input:
        return "Please enter a URL to flag."
    
    success, message = summarizer_instance.flag_url_to_csv(url_input)
    if success:
        return f"✅ {message}"
    else:
        return f"❌ {message}"

if __name__ == "__main__":
    # Example usage (for testing the new function)
    test_urls = [
        "https://www.google.com", # Should be high score
        "http://example.com/login", # Insecure, suspicious path
        "https://192.168.1.1/admin", # IP address, suspicious path
        "https://www.bankofamerica.secure.login.phishingsite.com", # Multiple subdomains, suspicious keywords
        "google.com", # Missing schema, but validatable
        "ftp://malware.com/evil.exe", # Invalid protocol
        "https://www.xn--pple-4xa.com/", # Punycode for apple.com
        "This is not a URL", # Completely invalid
        "javascript:alert('XSS');", # Dangerous characters
        "http://www.example.com", # Insecure
        "https://www.facebook.com/login.php?user=123&pass=abc", # Potentially suspicious form context
        "https://expired.badssl.com/", # Expired SSL
        "https://self-signed.badssl.com/" # Self-signed SSL
    ]

    # for u in test_urls:
    #     print(f"\n--- Analyzing URL: {u} ---")
    #     _, report = WebsiteSummarizer().summarize(u)
    #     print(report)

    # Gradio interface setup
    # We remove the OpenAI API key check for launching Gradio to allow flagging even if AI analysis is skipped.
    # The AI analysis itself will still be skipped if the key is not set.
    with gr.Blocks() as iface:
        gr.Markdown(
            """
            # Advanced Website Fraud Checker
            Enter a URL to get a comprehensive analysis for potential fraud or security risks.
            **Note:** Some checks require external API keys (Google Safe Browse, OpenAI).
            Fetching dynamic content uses headless Chrome, which may take a few seconds.
            """
        )
        url_input = gr.Textbox(lines=1, placeholder="Enter URL here...", label="Website URL")
        output_report = gr.Markdown(label="Website Analysis Report")
        output_flag_status = gr.Markdown(label="Flag Status") # New output for flag messages

        with gr.Row():
            analyze_btn = gr.Button("Analyze URL")
            flag_btn = gr.Button("Flag URL (Save to CSV)")

        analyze_btn.click(
            fn=analyze_url_gradio,
            inputs=url_input,
            outputs=output_report
        )
        flag_btn.click(
            fn=flag_current_url_gradio,
            inputs=url_input,
            outputs=output_flag_status # Link flag button to new output
        )

    iface.launch()
